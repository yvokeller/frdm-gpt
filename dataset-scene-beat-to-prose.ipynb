{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scene Beat to Prose\n",
    "\n",
    "Train the LLM to write paragraphs in my writing style, based on scene beats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated scene beats for chunk 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:06,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated scene beats for chunk 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:08,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated scene beats for chunk 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:11,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated scene beats for chunk 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:13,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated scene beats for chunk 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:16,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated scene beats for chunk 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:17,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated scene beats for chunk 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:20,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated scene beats for chunk 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:23,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated scene beats for chunk 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:26,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated scene beats for chunk 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:28,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated scene beats for chunk 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:30,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated scene beats for chunk 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:33,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated scene beats for chunk 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:36,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated scene beats for chunk 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:40,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated scene beats for chunk 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:42,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated scene beats for chunk 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:45,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated scene beats for chunk 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:49,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated scene beats for chunk 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:52,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated scene beats for chunk 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:55,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated scene beats for chunk 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:57,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated scene beats for chunk 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [01:00,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated scene beats for chunk 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [01:03,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated scene beats for chunk 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [01:07,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated scene beats for chunk 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [01:09,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated scene beats for chunk 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [01:12,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated scene beats for chunk 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [01:15,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated scene beats for chunk 26\n",
      "Scene beats generation completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from mlx_lm import load, generate\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from prompts import world_explanation\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "def separate_chapters(text):\n",
    "    chapters = []\n",
    "    lines = text.split('\\n')\n",
    "    current_chapter = []\n",
    "    weekdays = ['Montag', 'Dienstag', 'Mittwoch', 'Donnerstag', 'Freitag', 'Samstag', 'Sonntag']\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        if i < len(lines) - 1 and any(lines[i+1].startswith(day) for day in weekdays):\n",
    "            if current_chapter:\n",
    "                chapters.append('\\n'.join(current_chapter))\n",
    "                current_chapter = []\n",
    "        current_chapter.append(line)\n",
    "    \n",
    "    if current_chapter:\n",
    "        chapters.append('\\n'.join(current_chapter))\n",
    "    \n",
    "    return chapters\n",
    "\n",
    "def chunk_chapters(chapters, max_words=500):\n",
    "    chunked_chapters = []\n",
    "    for chapter in chapters:\n",
    "        lines = chapter.split('\\n')\n",
    "        current_chunk = []\n",
    "        word_count = 0\n",
    "        \n",
    "        for line in lines:\n",
    "            line_words = len(line.split())\n",
    "            if word_count + line_words > max_words:\n",
    "                if current_chunk:\n",
    "                    chunked_chapters.append('\\n'.join(current_chunk))\n",
    "                current_chunk = [line]\n",
    "                word_count = line_words\n",
    "            else:\n",
    "                current_chunk.append(line)\n",
    "                word_count += line_words\n",
    "        \n",
    "        if current_chunk:\n",
    "            chunked_chapters.append('\\n'.join(current_chunk))\n",
    "    \n",
    "    return chunked_chapters\n",
    "\n",
    "def paragraph_to_scene_beats(chunk, model, tokenizer, use_openai=False, openai_model=\"gpt-4o-mini\"):\n",
    "    prompt = f\"\"\"\n",
    "    Du bist ein professioneller Autor und arbeitest an einer Fantasy-Szene für den Roman \"ANSTURM\": {world_explanation}\n",
    "    \n",
    "    Vor dir liegt ein Textparagraph, und deine Aufgabe ist es, die zugrundeliegenden Scene Beats zu rekonstruieren. Jeder Beat sollte die Motivationen der Charaktere, die äusseren Umstände und das Ziel der Szene zusammenfassen, aber auf einfache und knappe Weise.\n",
    "\n",
    "    Hier ist ein Beispiel für Scene Beats, wie du sie schreiben sollst:\n",
    "\n",
    "    - Sokrate rennt verzweifelt durch die Dunkelheit, verfolgt von den Gedanken, dass er zu spät kommen könnte, um das Leben, das er kennt, zu retten. Er ist erschöpft, doch der Drang, die gesammelten Informationen weiterzugeben, treibt ihn an.\n",
    "    - Der Wald um ihn herum wird immer dunkler, der Mond geht auf, und damit erklingt das Heulen der Werwölfe in der Ferne. Er spürt die Bedrohung näherkommen, kämpft aber mit aller Kraft weiter. Die Schreie aus der Ferne holen ihn in die Realität zurück.\n",
    "    - Vor dem Portal ergreift er das Amulett. Er weiss, dass er das Portal damit öffnen kann, indem er es hinhält. Kurz danach wird er von einem Werwolf zu Boden gerissen. Schmerz durchfährt seinen Körper. Er erkennt, dass es kein Entkommen mehr gibt.\n",
    "    - Die Werwölfe umringen ihn, und der Anführer beißt zu. Mit dem letzten Gedanken an sein altes Ich, bevor er vollständig verwandelt wird, akzeptiert Sokrate, dass sein altes Leben endet.\n",
    "\n",
    "    Der Paragraph:\n",
    "\n",
    "    \"{chunk}\"\n",
    "\n",
    "    Antworte nur mit den Scene Beat(s), ohne weitere Einleitung oder Erklärung.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        if use_openai:\n",
    "            response = client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt\n",
    "                    }\n",
    "                ],\n",
    "                model=openai_model,\n",
    "                max_tokens=1000\n",
    "            )\n",
    "            scene_beats = response.choices[0].message.content\n",
    "        else:\n",
    "            messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "            prompt = tokenizer.apply_chat_template(\n",
    "                messages, tokenize=False, add_generation_prompt=True\n",
    "            )\n",
    "            scene_beats = generate(model, tokenizer, prompt=prompt, verbose=False, max_tokens=1000)\n",
    "        return scene_beats\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating rephrased text: {e}\")\n",
    "        return f\"EXCEPTION: {e}\"\n",
    "\n",
    "# Function to generate scene beats for chunks\n",
    "def generate_scene_beats(input_file, output_file):\n",
    "    # Load existing results if any\n",
    "    existing_results = {}\n",
    "    if os.path.exists(output_file):\n",
    "        with open(output_file, 'r') as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line)\n",
    "                existing_results[data['id']] = data\n",
    "\n",
    "    # Process chunks and generate scene beats\n",
    "    with open(input_file, 'r') as in_file, open(output_file, 'a') as out_file:\n",
    "        for line in tqdm(in_file):\n",
    "            data = json.loads(line)\n",
    "            chunk_id = data['id']\n",
    "            \n",
    "            # Skip if already processed\n",
    "            if chunk_id in existing_results:\n",
    "                continue\n",
    "            \n",
    "            scene_beats = paragraph_to_scene_beats(data['chunk'], model, tokenizer, use_openai=True)\n",
    "            print(f'Generated scene beats for chunk {chunk_id}')\n",
    "            \n",
    "            result = {\n",
    "                \"id\": chunk_id,\n",
    "                \"chunk\": data['chunk'],\n",
    "                \"scene_beats\": scene_beats\n",
    "            }\n",
    "            \n",
    "            json.dump(result, out_file)\n",
    "            out_file.write('\\n')\n",
    "            out_file.flush()  # Ensure data is written immediately\n",
    "\n",
    "CHUNK_CHAPTERS = False\n",
    "CHUNK_SIZE = 250\n",
    "VERSION = \"v2\"\n",
    "\n",
    "# Load model and tokenizer\n",
    "model, tokenizer = load(\"models/frdm-Llama-3.1-8B-Write\")\n",
    "\n",
    "# Read and process the text\n",
    "text = open('data/ansturm.txt', 'r').read()\n",
    "if CHUNK_CHAPTERS:\n",
    "    chapters = separate_chapters(text)\n",
    "    prose_paragraphs = chunk_chapters(chapters, max_words=CHUNK_SIZE)\n",
    "else:\n",
    "    prose_paragraphs = separate_chapters(text)\n",
    "\n",
    "# Save chunked chapters to a JSONL file\n",
    "chunked_file = f'data/chapters_{VERSION}.jsonl'\n",
    "with open(chunked_file, 'w') as f:\n",
    "    for i, chunk in enumerate(prose_paragraphs):\n",
    "        json.dump({\"id\": i, \"chunk\": chunk}, f)\n",
    "        f.write('\\n')\n",
    "\n",
    "# Generate scene beats\n",
    "output_file = f'data/chapters_with_beats_{VERSION}.jsonl'\n",
    "generate_scene_beats(chunked_file, output_file)\n",
    "\n",
    "print(\"Scene beats generation completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset creation completed.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def create_dataset_entry(scene_beats, paragraph):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Du bist der Fantasy-Autor Yvo K. Jedes Mal, wenn ich dir Scene Beats vorschreibe, schreibst du die komplette Szene auf der Grundlage der Idee. Schliesse die Szene nicht selbst ab, sondern halte dich genau an die Scene Beats.\"},\n",
    "        {\"role\": \"user\", \"content\": scene_beats},\n",
    "        {\"role\": \"assistant\", \"content\": paragraph}\n",
    "    ]\n",
    "    return json.dumps({\"messages\": messages})\n",
    "\n",
    "def create_dataset(input_file, output_file):\n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "        for line in infile:\n",
    "            data = json.loads(line)\n",
    "            dataset_entry = create_dataset_entry(data['scene_beats'], data['chunk'])\n",
    "            outfile.write(dataset_entry + '\\n')\n",
    "\n",
    "# Create the dataset\n",
    "input_file = f'data/chapters_with_beats_{VERSION}.jsonl'\n",
    "output_file = f'data/scene_beat_to_prose_dataset_{VERSION}.jsonl'\n",
    "create_dataset(input_file, output_file)\n",
    "\n",
    "print(\"Dataset creation completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-validation-test split created in data/frdm-Llama-3.1-8B-Write-Beat-to-Prose-v1\n",
      "Train samples: 190\n",
      "Validation samples: 23\n",
      "Test samples: 25\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "def create_train_valid_test_split(input_file, output_folder, train_ratio=0.8, valid_ratio=0.1, test_ratio=0.1, seed=42):\n",
    "    # Ensure ratios sum to 1\n",
    "    assert abs(train_ratio + valid_ratio + test_ratio - 1.0) < 1e-5, \"Ratios must sum to 1\"\n",
    "\n",
    "    # Create the output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Read all lines from the input file\n",
    "    with open(input_file, 'r') as infile:\n",
    "        lines = infile.readlines()\n",
    "\n",
    "    # Shuffle the lines\n",
    "    random.seed(seed)\n",
    "    random.shuffle(lines)\n",
    "\n",
    "    # Calculate split indices\n",
    "    train_split = int(len(lines) * train_ratio)\n",
    "    valid_split = train_split + int(len(lines) * valid_ratio)\n",
    "\n",
    "    # Split the data\n",
    "    train_data = lines[:train_split]\n",
    "    valid_data = lines[train_split:valid_split]\n",
    "    test_data = lines[valid_split:]\n",
    "\n",
    "    # Write train data\n",
    "    train_file = os.path.join(output_folder, 'train.jsonl')\n",
    "    with open(train_file, 'w') as outfile:\n",
    "        outfile.writelines(train_data)\n",
    "\n",
    "    # Write validation data\n",
    "    valid_file = os.path.join(output_folder, 'valid.jsonl')\n",
    "    with open(valid_file, 'w') as outfile:\n",
    "        outfile.writelines(valid_data)\n",
    "\n",
    "    # Write test data\n",
    "    test_file = os.path.join(output_folder, 'test.jsonl')\n",
    "    with open(test_file, 'w') as outfile:\n",
    "        outfile.writelines(test_data)\n",
    "\n",
    "    print(f\"Train-validation-test split created in {output_folder}\")\n",
    "    print(f\"Train samples: {len(train_data)}\")\n",
    "    print(f\"Validation samples: {len(valid_data)}\")\n",
    "    print(f\"Test samples: {len(test_data)}\")\n",
    "\n",
    "# Usage\n",
    "dataset_name = f\"frdm-Llama-3.1-8B-Write-Beat-to-Prose-{VERSION}\"\n",
    "\n",
    "input_file = f'data/scene_beat_to_prose_dataset_{VERSION}.jsonl'\n",
    "output_folder = f'data/{dataset_name}'\n",
    "create_train_valid_test_split(input_file, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: 'models/frdm-Llama-3.1-8B-Write-Beat-to-Prose-v1/0000095_adapters.safetensors/adapter_config.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Load models\u001b[39;00m\n\u001b[1;32m     18\u001b[0m raw_model, raw_tokenizer \u001b[38;5;241m=\u001b[39m load(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/frdm-Llama-3.1-8B-Write\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m fine_tuned_model, fine_tuned_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/frdm-Llama-3.1-8B-Write\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/frdm-Llama-3.1-8B-Write-Beat-to-Prose-v1/0000095_adapters.safetensors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Scene beats\u001b[39;00m\n\u001b[1;32m     22\u001b[0m scene_beats \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124m- Kontext: Fantasy Roman ANSTURM\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124m- Charaktere: Raven, Dusk, Caleor, alles Jungs in der 8. Klasse.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124m- Am Montag versammeln sich alle im Garten des Protagonisten, bereit für das Abenteuer. Das Wetter ist kühl, der Herbst kündigt den nahenden Winter an. Sie packen ihre Bikes und starten den Anstieg zu einem erhöhten Platz am See, während sie sich der winterlichen Berglandschaft nähern.\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/frdm-gpt-AIfW-Lx2-py3.10/lib/python3.10/site-packages/mlx_lm/utils.py:506\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path_or_hf_repo, tokenizer_config, model_config, adapter_path, lazy)\u001b[0m\n\u001b[1;32m    504\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(model_path, lazy, model_config)\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m adapter_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 506\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mapply_lora_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    508\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m load_tokenizer(model_path, tokenizer_config)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/frdm-gpt-AIfW-Lx2-py3.10/lib/python3.10/site-packages/mlx_lm/tuner/utils.py:170\u001b[0m, in \u001b[0;36mapply_lora_layers\u001b[0;34m(model, adapter_path)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m adapter_path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe adapter path does not exist: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madapter_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 170\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madapter_config.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[1;32m    171\u001b[0m     config \u001b[38;5;241m=\u001b[39m types\u001b[38;5;241m.\u001b[39mSimpleNamespace(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mjson\u001b[38;5;241m.\u001b[39mload(fid))\n\u001b[1;32m    172\u001b[0m linear_to_lora_layers(\n\u001b[1;32m    173\u001b[0m     model,\n\u001b[1;32m    174\u001b[0m     config\u001b[38;5;241m.\u001b[39mlora_layers,\n\u001b[1;32m    175\u001b[0m     config\u001b[38;5;241m.\u001b[39mlora_parameters,\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_dora\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m    177\u001b[0m )\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: 'models/frdm-Llama-3.1-8B-Write-Beat-to-Prose-v1/0000095_adapters.safetensors/adapter_config.json'"
     ]
    }
   ],
   "source": [
    "# Model inference\n",
    "from mlx_lm import load, generate\n",
    "import json\n",
    "\n",
    "def generate_scene(model, tokenizer, scene_beats, max_tokens=1024, temp=0.5):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Du bist der Fantasy-Autor Yvo K. Jedes Mal, wenn ich dir einen Scene Beat vorschreibe, schreibst du die komplette Szene auf der Grundlage der Idee. Schliesse die Szene nicht selbst ab, sondern halte dich genau an die Scene Beats. Schliesse nicht mit einer Vorahnung ab.\"},\n",
    "        {\"role\": \"user\", \"content\": scene_beats}\n",
    "    ]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    return generate(model, tokenizer, prompt=json.dumps(prompt), max_tokens=max_tokens, temp=temp, verbose=True)\n",
    "\n",
    "# Load models\n",
    "raw_model, raw_tokenizer = load(\"models/frdm-Llama-3.1-8B-Write\")\n",
    "fine_tuned_model, fine_tuned_tokenizer = load(\"models/frdm-Llama-3.1-8B-Write\", adapter_path=\"models/frdm-Llama-3.1-8B-Write-Beat-to-Prose-v1\")\n",
    "\n",
    "# Scene beats\n",
    "scene_beats = \"\"\"\n",
    "- Kontext: Fantasy Roman ANSTURM\n",
    "- Charaktere: Raven, Dusk, Caleor, alles Jungs in der 8. Klasse.\n",
    "- Perspektive: 1. Person Sicht Caleor, männlich, Ich-Erzähler\n",
    "- Zeitform: Präsens\n",
    "- Raven übernimmt die Kontrolle und stellt eine zynische Frage, die die Unlogik der Situation hervorhebt. Er ist frustriert und handelt impulsiv, indem er die Schlüssel an sich reißt und die Tür zuschlägt, bevor er entschlossen Richtung Büro des Schulleiters geht.\n",
    "- Die restliche Gruppe bleibt zurück. Der Protagonist Caleor lenkt die Aufmerksamkeit auf die bevorstehenden Ferien und versucht, die Stimmung aufzuhellen, indem er die anderen nach Plänen fragt.\n",
    "- Dusk schlägt eine Biketour in die Berge vor, die an einen schönen Ort führt, den sie letztes Jahr entdeckt haben. Die Gruppe beginnt, praktische Details zu planen, um das Abenteuer vorzubereiten.\n",
    "- Am Montag versammeln sich alle im Garten des Protagonisten, bereit für das Abenteuer. Das Wetter ist kühl, der Herbst kündigt den nahenden Winter an. Sie packen ihre Bikes und starten den Anstieg zu einem erhöhten Platz am See, während sie sich der winterlichen Berglandschaft nähern.\n",
    "\"\"\"\n",
    "\n",
    "raw_scene = generate_scene(raw_model, raw_tokenizer, scene_beats)\n",
    "fine_tuned_scene = generate_scene(fine_tuned_model, fine_tuned_tokenizer, scene_beats, temp=0.4)\n",
    "\n",
    "# Generate scenes\n",
    "print(\"Raw model:\")\n",
    "print(raw_scene)\n",
    "print(\"\\n\\n\")\n",
    "print(\"Fine-tuned model:\")\n",
    "print(fine_tuned_scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Prompt: \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\nYou are the fantasy author Yvo K. Each time I prompt you with a scene beat, write the full scene based on the idea. Do not conclude the scene on your own, follow the beat instructions closely. Do not end with foreshadowing.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n- Kontext: Fantasy Roman ANSTURM\\n- Charaktere: Raven, Dusk, Caleor, alles Jungs in der 8. Klasse.\\n- Perspektive: 1. Person Sicht Caleor, m\\u00e4nnlich, Ich-Erz\\u00e4hler\\n- Zeitform: Gegenwart\\n- Raven \\u00fcbernimmt die Kontrolle und stellt eine zynische Frage, die die Unlogik der Situation hervorhebt. Er ist frustriert und handelt impulsiv, indem er die Schl\\u00fcssel an sich rei\\u00dft und die T\\u00fcr zuschl\\u00e4gt, bevor er entschlossen Richtung B\\u00fcro des Schulleiters geht.\\n- Die restliche Gruppe bleibt zur\\u00fcck. Der Protagonist Caleor lenkt die Aufmerksamkeit auf die bevorstehenden Ferien und versucht, die Stimmung aufzuhellen, indem er die anderen nach Pl\\u00e4nen fragt.\\n- Dusk schl\\u00e4gt eine Biketour in die Berge vor, die an einen sch\\u00f6nen Ort f\\u00fchrt, den sie letztes Jahr entdeckt haben. Die Gruppe beginnt, praktische Details zu planen, um das Abenteuer vorzubereiten.\\n- Am Montag versammeln sich alle im Garten des Protagonisten, bereit f\\u00fcr das Abenteuer. Das Wetter ist k\\u00fchl, der Herbst k\\u00fcndigt den nahenden Winter an. Sie packen ihre Bikes und starten den Anstieg zu einem erh\\u00f6hten Platz am See, w\\u00e4hrend sie sich der winterlichen Berglandschaft n\\u00e4hern.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
      "Was sollen wir denn alles tun? Wir werden uns in den Bergen totlaufen, ein paar Stunden lang die Berge erkunden und dann wieder zurückkehren. Das ist doch alles nur ein Vorwand, um eine Biketour zu machen. Das ist doch das Gleiche, wie wenn wir einfach auf dem Radweg entlangfahren würden. Was ist das Besondere an diesem Ort? Was ist so besonders an diesem schönen Ort, den wir letztes Jahr entdeckt haben? Wir werden ihn wieder entdecken, wenn wir ihn erreichen. Das ist doch alles nur ein Haufen Unsinn. Wir sollten uns lieber in den Garten setzen und ein bisschen spielen, statt uns so viel Zeit und Mühe zu geben, um an einen Ort zu gelangen, der uns doch sowieso wieder verlassen wird. Ich werde ihn nicht mehr als ein Tag lang haben, und dann ist er wieder weg. Ich werde ihn nicht mehr als 24 Stunden lang haben, und dann ist er wieder weg. Das ist doch alles nur ein Haufen Unsinn. Wir sollten uns lieber in den Garten setzen und ein bisschen spielen, statt uns so viel Zeit und Mühe zu geben, um an einen Ort zu gelangen, der uns doch sowieso wieder verlassen wird. Ich werde ihn nicht mehr als ein Tag lang haben, und dann ist er wieder weg. Das ist doch alles nur ein Haufen Unsinn. Wir sollten uns lieber in den Garten setzen und ein bisschen spielen, statt uns so viel Zeit und Mühe zu geben, um an einen Ort zu gelangen, der uns doch sowieso wieder verlassen wird. Ich werde ihn nicht mehr als ein Tag lang haben, und dann ist er wieder weg. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn.\n",
      "==========\n",
      "Prompt: 508 tokens, 544.160 tokens-per-sec\n",
      "Generation: 954 tokens, 33.829 tokens-per-sec\n",
      "Peak memory: 39.732 GB\n"
     ]
    }
   ],
   "source": [
    "fine_tuned_scene = generate_scene(fine_tuned_model, fine_tuned_tokenizer, scene_beats, temp=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Was sollen wir denn alles tun? Wir werden uns in den Bergen totlaufen, ein paar Stunden lang die Berge erkunden und dann wieder zurückkehren. Das ist doch alles nur ein Vorwand, um eine Biketour zu machen. Das ist doch das Gleiche, wie wenn wir einfach auf dem Radweg entlangfahren würden. Was ist das Besondere an diesem Ort? Was ist so besonders an diesem schönen Ort, den wir letztes Jahr entdeckt haben? Wir werden ihn wieder entdecken, wenn wir ihn erreichen. Das ist doch alles nur ein Haufen Unsinn. Wir sollten uns lieber in den Garten setzen und ein bisschen spielen, statt uns so viel Zeit und Mühe zu geben, um an einen Ort zu gelangen, der uns doch sowieso wieder verlassen wird. Ich werde ihn nicht mehr als ein Tag lang haben, und dann ist er wieder weg. Ich werde ihn nicht mehr als 24 Stunden lang haben, und dann ist er wieder weg. Das ist doch alles nur ein Haufen Unsinn. Wir sollten uns lieber in den Garten setzen und ein bisschen spielen, statt uns so viel Zeit und Mühe zu geben, um an einen Ort zu gelangen, der uns doch sowieso wieder verlassen wird. Ich werde ihn nicht mehr als ein Tag lang haben, und dann ist er wieder weg. Das ist doch alles nur ein Haufen Unsinn. Wir sollten uns lieber in den Garten setzen und ein bisschen spielen, statt uns so viel Zeit und Mühe zu geben, um an einen Ort zu gelangen, der uns doch sowieso wieder verlassen wird. Ich werde ihn nicht mehr als ein Tag lang haben, und dann ist er wieder weg. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn. Das ist doch alles nur ein Haufen Unsinn.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tuned_scene"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frdm-gpt-AIfW-Lx2-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
